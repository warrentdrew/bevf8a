batch_size: 1 # 8 gpu, total bs: 8
epochs: 24

train_dataset:
  type: AT128DatasetValid
  data_root: ./data
  use_valid_flag: True
  num_views: 6
  ann_file: ./data/at128/at128_hesai128_train_52000_early_fusion.pkl
  load_interval: 1
  classes: [
            'bigMot', 'smallMot', 'nonMot', 'pedestrian', 'TrainedOthers'
        ]
  modality: 
    use_lidar: True
    use_camera: True
    use_radar: False
    use_map: False
    use_external: False
  test_mode: False
  box_type_3d: 'LiDAR'
  pipeline:
    - type: LoadMultiViewImageFromZipFiles
      to_float32: true
    - type: LoadAnnotations3D_valid
      with_bbox_3d: true
      with_label_3d: true
    - type: ObjectRangeFilter_valid
      point_cloud_range: [-120, -120, -5, 120, 120, 3]
    - type: ObjectNameFilter_valid
      classes: ['bigMot', 'smallMot', 'nonMot', 'pedestrian',
                    'TrainedOthers'
                ]
    - type: RandomScaleImageMultiViewImage
      scales: [0.1, 0.4]
    - type: MyNormalize
      mean: [123.675, 116.28, 103.53]
      std: [58.395, 57.12, 57.375]
      to_rgb: true
    - type: MyPad
      size_divisor: 32
    - type: DefaultFormatBundle3D_valid
      class_names: [
                    'bigMot', 'smallMot', 'nonMot', 'pedestrian',
                    'TrainedOthers'
                ]
    - type: SampleFilterByKey
      keys: ['img', 'gt_bboxes_3d', 'gt_labels_3d', 'valid_flag']
  eval_configs: 
    class_range:
      TrainedOthers: 120
      pedestrian: 120
      bigMot: 120
      smallMot: 120
      nonMot: 120
    distances: [[0, 15], [15, 40], [40, 60], [60, 80], [80, 100], [100, 120]]
    rel_dist_fcn: 'relative_center_distance'
    rel_dist_th_tp: 0.1
    ab_dist_th_tp: 1.5
    iou_th_hard_tp: 0.5
    iou_th_easy_tp: 0.2
    rel_ab_th: 15
    iou_type: 'geo_iou'
    iou_matrix_path: 'piou_matrix.pkl'
    geo_iou_type: 'bev_iou'
    min_recall: 0.0
    min_precision: 0.0
    max_boxes_per_sample: 500
    ignore_gt_valid: False
    score_thr: 0.1
    fuse_mot: False
    cross_cls_match: False
    score_first: False
    dist_type: 'geo_dist'
    pts_dist_path: 'dist_infos.pkl'
    render_curves: False
    metric: ['camera']
  
val_dataset:
  type: AT128DatasetValid
  data_root: ./data
  use_valid_flag: True
  num_views: 6
  ann_file: ./data/at128/at128_test_2067_early_fusion.pkl
  load_interval: 1
  classes: [
            'bigMot', 'smallMot', 'nonMot', 'pedestrian', 'TrainedOthers'
        ]
  modality: 
    use_lidar: True
    use_camera: True
    use_radar: False
    use_map: False
    use_external: False
  test_mode: True
  box_type_3d: 'LiDAR'
  pipeline:
    - type: LoadPointsFromZipFile
      coord_type: 'LIDAR'
      load_dim: 4
      use_dim: 4
    - type: LoadMultiViewImageFromZipFiles
      to_float32: true
    - type: MultiScaleFlipAug3D
      img_scale: (720, 465) #not list
      pts_scale_ratio: 1
      flip: False
      transforms:
        - type: RandomScaleImageMultiViewImage
          scales: [0.22]
        - type: MyNormalize
          mean: [123.675, 116.28, 103.53]
          std: [58.395, 57.12, 57.375]
          to_rgb: true
        - type: MyPad
          size_divisor: 32
        - type: DefaultFormatBundle3D
          class_names: [
                        'bigMot', 'smallMot', 'nonMot', 'pedestrian',
                        'TrainedOthers'
                    ]
          with_label: False
        - type: SampleFilterByKey
          keys: ['points', 'img']
  eval_configs: 
    class_range:
      TrainedOthers: 120
      pedestrian: 120
      bigMot: 120
      smallMot: 120
      nonMot: 120
    distances: [[0, 15], [15, 40], [40, 60], [60, 80], [80, 100], [100, 120]]
    rel_dist_fcn: 'relative_center_distance'
    rel_dist_th_tp: 0.1
    ab_dist_th_tp: 1.5
    iou_th_hard_tp: 0.5
    iou_th_easy_tp: 0.2
    rel_ab_th: 15
    iou_type: 'geo_iou'
    iou_matrix_path: 'piou_matrix.pkl'
    geo_iou_type: 'bev_iou'
    min_recall: 0.0
    min_precision: 0.0
    max_boxes_per_sample: 500
    ignore_gt_valid: False
    score_thr: 0.1
    fuse_mot: False
    cross_cls_match: False
    score_first: False
    dist_type: 'geo_dist'
    pts_dist_path: 'dist_infos.pkl'
    render_curves: False
    metric: ['camera']

model:
  type: BEVFFasterRCNNV1
  bias_lr_factor: 0.1
  camera_stream: true
  grid: 0.6
  num_views: 6
  final_dim: [1860, 2880]
  pc_range: [-120.0, -120.0, -5.0, 120.0, 120.0, 3.0]
  bev_h: 144
  bev_w: 144
  downsample: 16
  dla_add_extra_conv: True
  cam_only: true
  norm_decay: 0.0
  img_backbone:
      type: DLASeg
      channels: [16, 32, 64, 64, 128, 256]
      output_levels: 1
      norm_decay: 0.0
  cam2bev_modules:
      type: UniformBevGridTransformer
      lss: False
      use_conv_bevencoder: False
      point_cloud_range: [-120.0, -120.0, -5.0, 120.0, 120.0, 3.0]
      bev_h: 144
      bev_w: 144
      norm_decay: 0.0
      positional_encoding:
        type: 'SinePositionalEncoding'
        num_feats: 128
        normalize: True
      transformer:
        type: 'PerceptionTransformer'
        num_feature_levels: 1
        num_cams: 6
        embed_dims: 256
        rotate_prev_bev: False
        use_shift: True
        use_can_bus: False
        can_bus_norm: False
        use_cams_embeds: True
        rotate_center: [100, 100]
        use_decoder: False
        norm_decay: 0.0
        encoder:
          type: 'BEVFormerEncoder'
          num_layers: 1
          point_cloud_range: [-120.0, -120.0, -5.0, 120.0, 120.0, 3.0]
          num_points_in_pillar: 4
          return_intermediate: False
          transformerlayers:
            type_name: 'BEVFormerLayer'
            norm_decay: 0.0
            attn_cfgs:  [
              {
                type_name: 'SpatialCrossAttention',
                point_cloud_range: [-120.0, -120.0, -5.0, 120.0, 120.0, 3.0],
                deformable_attention: {
                  type_name: 'MSDeformableAttention3D',
                  embed_dims: 256,
                  num_points: 8,
                  num_levels: 1
                },
                embed_dims: 256
              }
            ]
            feedforward_channels: 512
            ffn_dropout: 0.1
            operation_order: ['cross_attn', 'norm', 'ffn', 'norm']      
  pts_bbox_head:
    type: 'BEVFormerHead'
    bev_h: 144
    bev_w: 144
    num_classes: 5
    in_channels: 256
    num_query: 900
    sync_cls_avg_factor: True
    with_box_refine: True
    as_two_stage: False
    norm_decay: 0.0
    positional_encoding:
      type: 'SinePositionalEncoding'
      num_feats: 128
      normalize: True
    transformer:
      type: 'PerceptionTransformerDecoder'
      rotate_prev_bev: True
      use_shift: True
      use_can_bus: False
      embed_dims: 256
      norm_decay: 0.0
      decoder:
        type: 'DetectionTransformerDecoder'
        num_layers: 6
        return_intermediate: True
        transformerlayers:
          type_name: 'DetrTransformerDecoderLayer'
          norm_decay: 0.0
          attn_cfgs: [
            {
              type_name: 'MultiheadAttention',
              embed_dims: 256,
              num_heads: 8,
              dropout: 0.1
            },
            {
              type_name: 'CustomMSDeformableAttention',
              embed_dims: 256,
              num_levels: 1
            },
          ]
          feedforward_channels: 512
          ffn_dropout: 0.1
          operation_order: ['self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm']
    bbox_coder:
      type: 'NMSFreeCoder'
      post_center_range: [-131.8, -131.8, -10.0, 131.8, 131.8, 10.0]
      point_cloud_range: [-120.0, -120.0, -5.0, 120.0, 120.0, 3.0]
      max_num: 300
      voxel_size: [0.2083, 0.2083, 8]
      num_classes: 5
    loss_cls:
      type: 'WeightedFocalLoss'
      use_sigmoid: True
      gamma: 2.0
      alpha: 0.25
      loss_weight: 2.0
    loss_bbox:
      type: 'L1Loss'
      loss_weight: 0.25
    loss_iou:
      type: 'GIoULoss'
      loss_weight: 0.0
    assigner:
      type: 'HungarianAssigner3DFromBEVFormer'
      cls_cost:
        type: 'FocalLossCost'
        weight: 2.0
      reg_cost:
        type: 'BBox3DL1Cost'
        weight: 0.25
      iou_cost:
        type: 'IoUCost'
        weight: 0.0 # Fake cost. This is just to make it compatible with DETR head.
      pc_range: [-120.0, -120.0, -5.0, 120.0, 120.0, 3.0]
    sampler:
      type: 'PseudoSampler'
  pretrained: pretrained/epoch_12.pdparams

optimizer:
  type: AdamW
  beta1: 0.9
  beta2: 0.999
  weight_decay: 0.05
  grad_clip:
    type: ClipGradByGlobalNorm
    clip_norm: 35

lr_scheduler:
  type: LinearWarmup
  learning_rate:
    type: CosineAnnealingDecayByEpoch
    learning_rate: 0.0002
    T_max: 24
    eta_min: 2.0e-7
  warmup_steps: 500
  start_lr: 0.0000666666667
  end_lr: 0.0002
